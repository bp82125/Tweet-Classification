{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "df = pd.read_csv('../processed_data.csv')\n",
    "\n",
    "X = df['text']\n",
    "y = df['target']\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [word_tokenize(sentence.lower()) for sentence in X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length: 21\n"
     ]
    }
   ],
   "source": [
    "max_length = max(len(sentence) for sentence in tokenized_texts)\n",
    "print(\"Maximum sentence length:\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    sentences=tokenized_texts, vector_size=300, window=21, min_count=1, sg=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, model):\n",
    "    words = word_tokenize(text.lower())\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    return (\n",
    "        np.mean(word_vectors, axis=0) if word_vectors else np.zeros(model.vector_size)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized data shape:  (7593, 300)\n",
      "Number of classes:  2\n"
     ]
    }
   ],
   "source": [
    "X_vectorized = np.array([vectorize_text(text, w2v_model) for text in X])\n",
    "\n",
    "print(\"Vectorized data shape: \", X_vectorized.shape)\n",
    "print(\"Number of classes: \", len(y.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../saved_models/word2vec\"\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
    "    \"Bayes\": GaussianNB(),  # Sử dụng mô hình Gaussian Naive Bayes vì Multinomial không hỗ trợ giá trị âm\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=50, min_samples_split=4, criterion='gini', random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, max_depth=100, min_samples_split=4, criterion='entropy'),\n",
    "    \"Logistic Regression\": LogisticRegression(C=0.1, random_state=42, max_iter=1000),\n",
    "    \"SVM Linear\": SVC(kernel='linear', C=1.0, random_state=42),\n",
    "    \"SVM Non-linear\": SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model KNN saved to ../saved_models/word2vec/KNN.joblib\n",
      "Model Bayes saved to ../saved_models/word2vec/Bayes.joblib\n",
      "Model Decision Tree saved to ../saved_models/word2vec/Decision Tree.joblib\n",
      "Model Random Forest saved to ../saved_models/word2vec/Random Forest.joblib\n",
      "Model Logistic Regression saved to ../saved_models/word2vec/Logistic Regression.joblib\n",
      "Model SVM Linear saved to ../saved_models/word2vec/SVM Linear.joblib\n",
      "Model SVM Non-linear saved to ../saved_models/word2vec/SVM Non-linear.joblib\n",
      "KNN Mean Metrics:\n",
      "  Accuracy: 0.6447\n",
      "  Precision: 0.6350\n",
      "  Recall: 0.4132\n",
      "  F1 Score: 0.5003\n",
      "\n",
      "Bayes Mean Metrics:\n",
      "  Accuracy: 0.5280\n",
      "  Precision: 0.4678\n",
      "  Recall: 0.6919\n",
      "  F1 Score: 0.5581\n",
      "\n",
      "Decision Tree Mean Metrics:\n",
      "  Accuracy: 0.6376\n",
      "  Precision: 0.5800\n",
      "  Recall: 0.5769\n",
      "  F1 Score: 0.5783\n",
      "\n",
      "Random Forest Mean Metrics:\n",
      "  Accuracy: 0.7248\n",
      "  Precision: 0.7744\n",
      "  Recall: 0.5106\n",
      "  F1 Score: 0.6151\n",
      "\n",
      "Logistic Regression Mean Metrics:\n",
      "  Accuracy: 0.5639\n",
      "  Precision: 0.3957\n",
      "  Recall: 0.0227\n",
      "  F1 Score: 0.0428\n",
      "\n",
      "SVM Linear Mean Metrics:\n",
      "  Accuracy: 0.5731\n",
      "  Precision: 1.0000\n",
      "  Recall: 0.0092\n",
      "  F1 Score: 0.0183\n",
      "\n",
      "SVM Non-linear Mean Metrics:\n",
      "  Accuracy: 0.5691\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1 Score: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "metrics = {model_name: {'accuracy': [], 'precision': [],\n",
    "                        'recall': [], 'f1': []} for model_name in models.keys()}\n",
    "\n",
    "for _ in range(20):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_vectorized, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        if model_name == \"Logistic Regression\":\n",
    "            y_prob = model.predict_proba(X_test)[:, 1]\n",
    "            y_pred = (y_prob >= 0.5).astype(int)\n",
    "        else:\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='binary', zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, average='binary', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='binary', zero_division=0)\n",
    "\n",
    "        metrics[model_name]['accuracy'].append(accuracy)\n",
    "        metrics[model_name]['precision'].append(precision)\n",
    "        metrics[model_name]['recall'].append(recall)\n",
    "        metrics[model_name]['f1'].append(f1)\n",
    "\n",
    "mean_metrics = {model_name: {metric: np.mean(values) for metric, values in model_metrics.items()}\n",
    "                for model_name, model_metrics in metrics.items()}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model_filename = os.path.join(save_path, f\"{model_name}.joblib\")\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"Model {model_name} saved to {model_filename}\")\n",
    "\n",
    "for model_name, mean in mean_metrics.items():\n",
    "    print(f\"{model_name} Mean Metrics:\")\n",
    "    print(f\"  Accuracy: {mean['accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {mean['precision']:.4f}\")\n",
    "    print(f\"  Recall: {mean['recall']:.4f}\")\n",
    "    print(f\"  F1 Score: {mean['f1']:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
